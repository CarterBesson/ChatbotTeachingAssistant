#Tests Generated by ChatGPT
import unittest
from unittest.mock import patch, MagicMock

# Import the get_embeddings function from embeddings_generator module
from backend.database.embeddings_generator import get_embeddings

class TestGetEmbeddings(unittest.TestCase):
    @patch('backend.database.embeddings_generator.openai.embeddings.create')
    def test_get_embeddings_success(self, mock_create):
        # Sample input data
        text_chunks = ['Hello world', 'Testing embeddings', 'Unit tests are important']
        batch_size = 2

        # Define a side effect function for the mock
        def mock_api_call(input, model):
            # 'input' is the batch of text chunks
            mock_resp = MagicMock()
            mock_resp.data = [
                MagicMock(embedding=[0.1, 0.2, 0.3]) for _ in input
            ]
            return mock_resp

        # Configure the mock to use the side effect function
        mock_create.side_effect = mock_api_call

        # Call the function under test
        embeddings = get_embeddings(text_chunks, batch_size=batch_size)

        # Assertions to verify the function's behavior
        self.assertEqual(len(embeddings), len(text_chunks))
        for i, embedding_info in enumerate(embeddings):
            self.assertIsNotNone(embedding_info['embedding'])
            self.assertEqual(embedding_info['text'], text_chunks[i])

        # Verify that openai.embeddings.create was called correctly
        expected_calls = (len(text_chunks) - 1) // batch_size + 1
        self.assertEqual(mock_create.call_count, expected_calls)

    @patch('backend.database.embeddings_generator.openai.embeddings.create')
    def test_get_embeddings_api_exception(self, mock_create):
        # Sample input data
        text_chunks = ['This will cause an exception']

        # Configure the mock to raise an exception
        mock_create.side_effect = Exception('API Error')

        # Call the function under test
        embeddings = get_embeddings(text_chunks)

        # Assertions to verify exception handling
        self.assertEqual(len(embeddings), len(text_chunks))
        for embedding_info in embeddings:
            self.assertIsNone(embedding_info['embedding'])
            self.assertEqual(embedding_info['text'], text_chunks[0])
            self.assertIn('error', embedding_info)
            self.assertEqual(embedding_info['error'], 'API Error')

    @patch('backend.database.embeddings_generator.openai.embeddings.create')
    def test_get_embeddings_empty_input(self, mock_create):
        # Empty input
        text_chunks = []

        # Call the function under test
        embeddings = get_embeddings(text_chunks)

        # Assertions
        self.assertEqual(embeddings, [])
        # Ensure the API is not called
        mock_create.assert_not_called()

    @patch('backend.database.embeddings_generator.openai.embeddings.create')
    def test_get_embeddings_large_input(self, mock_create):
        # Large input data
        text_chunks = [f'Text chunk {i}' for i in range(100)]
        batch_size = 10

        # Mocked response for each batch
        def mock_api_call(*args, **kwargs):
            batch = kwargs['input']
            mock_resp = MagicMock()
            mock_resp.data = [
                MagicMock(embedding=[0.1, 0.2, 0.3]) for _ in range(len(batch))
            ]
            return mock_resp

        mock_create.side_effect = mock_api_call

        # Call the function under test
        embeddings = get_embeddings(text_chunks, batch_size=batch_size)

        # Assertions
        self.assertEqual(len(embeddings), len(text_chunks))
        for i, embedding_info in enumerate(embeddings):
            self.assertIsNotNone(embedding_info['embedding'])
            self.assertEqual(embedding_info['text'], text_chunks[i])

        # Verify that openai.embeddings.create was called the correct number of times
        expected_calls = (len(text_chunks) - 1) // batch_size + 1
        self.assertEqual(mock_create.call_count, expected_calls)

    @patch('backend.database.embeddings_generator.openai.embeddings.create')
    def test_get_embeddings_different_batch_sizes(self, mock_create):
        # Input data
        text_chunks = ['Sample text 1', 'Sample text 2', 'Sample text 3', 'Sample text 4']

        # Test different batch sizes
        for batch_size in [1, 2, 3, 4, 5]:
            with self.subTest(batch_size=batch_size):
                # Reset mock
                mock_create.reset_mock()

                # Mocked response for each batch
                def mock_api_call(*args, **kwargs):
                    batch = kwargs['input']
                    mock_resp = MagicMock()
                    mock_resp.data = [
                        MagicMock(embedding=[0.1, 0.2, 0.3]) for _ in range(len(batch))
                    ]
                    return mock_resp

                mock_create.side_effect = mock_api_call

                # Call the function under test
                embeddings = get_embeddings(text_chunks, batch_size=batch_size)

                # Assertions
                self.assertEqual(len(embeddings), len(text_chunks))
                for i, embedding_info in enumerate(embeddings):
                    self.assertIsNotNone(embedding_info['embedding'])
                    self.assertEqual(embedding_info['text'], text_chunks[i])

                # Verify that openai.embeddings.create was called the correct number of times
                expected_calls = (len(text_chunks) - 1) // batch_size + 1
                self.assertEqual(mock_create.call_count, expected_calls)

if __name__ == '__main__':
    unittest.main()